#!/usr/bin/env python3
#   Este nodo se suscribe a una imagen de ROS, la convierte en una matriz de
#   OpenCV y la muestra en pantalla
import rospy
import cv2
import numpy as np
from sensor_msgs.msg import Image
from cv_bridge import CvBridge


from geometry_msgs.msg import Twist
from sensor_msgs.msg import LaserScan



import rospkg
rospack = rospkg.RosPack()
REFERENCE_IMAGE = rospack.get_path('autlab3') + '/src/images/can.png'
BACK_IMAGE = rospack.get_path('autlab3') + '/src/images/can_background.png'


class Lidar(object):
    
    
  def __init__(self):
    # Crear el suscriptor al tópico del LiDAR
    self.sub = rospy.Subscriber("scan", LaserScan, self.callback)

    # Esperar 1 segundo
    rospy.sleep(1)
    
    # Precalcular un vector de numpy que contenga los ángulos para cada
    # rango. Se puede usar numpy.arange, por ejemplo
    self.range_max = 0.0
    self.range_min = 0.0
    self.angle_min = 0.0
    self.angle_increment = 0.0
    self.mediciones = []
    self.x = []
    self.y = []
    
    # Se inicializa la lista de puntos cartesianos
    #cartesian_points = np.array([0, 0])
        

    
    # Almacenar los rangos máximo y mínimo que puede leer el LiDAR
       
  def callback(self, msg):
    # Callback para el suscriptor
    
    # rangos máximo y mínimo que puede leer el LiDAR
    self.max_range = msg.range_max # 3.5
    self.min_range = msg.range_min # 0.11999999731779099
    
    # Angulo minimo
    self.angle_min = msg.angle_min
    
    # Incremento angular
    self.angle_increment = msg.angle_increment
    
    # Mediciones
    self.mediciones = msg.ranges  
    self.close_point = np.min(msg.ranges)
    print(self.close_point)
        

class Cam(object):
  def __init__(self, topic_name="camera_frame"):
    self.bridge = CvBridge()
    self.image = np.zeros((10,10))
    isub = rospy.Subscriber(topic_name, Image, self.image_callback)

  def image_callback(self, img):
    self.image = self.bridge.imgmsg_to_cv2(img, "bgr8")

  def get_image(self):
    return self.image


if __name__ == '__main__':

  # Inicializar el nodo de ROS
  rospy.init_node('camera_node')

  # Objeto que se suscribe al tópico de la cámara
  topic_name = "/camera/rgb/image_raw"
  cam = Cam(topic_name)

  # Tópico para publicar una imagen de salida
  topic_pub = 'image_out'
  pubimg = rospy.Publisher(topic_pub, Image, queue_size=10)

  # Frecuencia del bucle principal
  freq = 10
  rate = rospy.Rate(freq)
  # Bucle principal

  # Para el movimiento
  pub = rospy.Publisher('cmd_vel', Twist, queue_size=10)  
  twist = Twist()

  # lidar
  # Objeto que lee el escaneo
  lidar = Lidar()

  # Set up
  #sharpen filter
  filter = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])

  MIN_NUM_GOOD_MATCHES = 10
  sift = cv2.xfeatures2d.SIFT_create()
  I1 = cv2.imread('images/can.png', cv2.IMREAD_GRAYSCALE)
  I1 = cv2.filter2D(I1,-1,filter)

  # I1 = cv2.GaussianBlur(I1,(3,3),cv2.BORDER_DEFAULT)
  object_detected = 0
  close = 0
  angular = -0.152
  while not rospy.is_shutdown():
    
    # Obtener la imagen del tópico de ROS en formato de OpenCV
    I = cam.get_image()
    
    # Realizar algún tipo de procesamiento sobre la imagen
    
    if (I.shape[1]>10):
      I2 = cv2.cvtColor(I, cv2.COLOR_BGR2GRAY)
      I2 = cv2.filter2D(I2,-1,filter)

      # I2 = cv2.GaussianBlur(I2,(3,3),cv2.BORDER_DEFAULT)
  
      keypts1, descriptores1 = sift.detectAndCompute(I1, None)
      keypts2, descriptores2 = sift.detectAndCompute(I2, None)

      # Parámetros de correspondencia usando FLANN
      FLANN_INDEX_KDTREE = 1
      index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)
      search_params = dict(checks=50)
      # Correspondencia usando FLANN
      flann = cv2.FlannBasedMatcher(index_params, search_params)
      matches = flann.knnMatch(descriptores1, descriptores2, k=2)

      # Correspondencias adecuadas según el ratio
      good_matches = []
      for m, n in matches:
          if m.distance < 0.7 * n.distance:
              good_matches.append(m)

      # print(len(good_matches))

      if len(good_matches) >= MIN_NUM_GOOD_MATCHES:
        object_detected = 1
        # Coordenadas 2D de los correspondientes keypoints 
        src_pts = np.float32( [keypts1[m.queryIdx].pt for m in good_matches] ).reshape(-1, 1, 2)
        dst_pts = np.float32( [keypts2[m.trainIdx].pt for m in good_matches] ).reshape(-1, 1, 2)

        # Homografía
        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)
        mask_matches = mask.ravel().tolist()

        # Transformación de perspectiva: proyectar los bordes rectangulares
        # en la escena para dibujar un borde
        h, w = I1.shape
        src_corners = np.float32([[0, 0], [0, h-1], [w-1, h-1], [w-1, 0]]).reshape(-1, 1, 2)
        dst_corners = cv2.perspectiveTransform(src_corners, M)
        dst_corners = dst_corners.astype(np.int32)

        # Dibujar los bordes de la región correspondiente
        num_corners = len(dst_corners)
        for i in range(num_corners):
            x0, y0 = dst_corners[i][0]
            if i == num_corners - 1:
                next_i = 0
            else:
                next_i = i + 1
            x1, y1 = dst_corners[next_i][0]
            cv2.line(I2, (x0, y0), (x1, y1), 255, 3, cv2.LINE_AA)

        # Dibujar correspondencias que pasaron el test de ratio
        img_matches = cv2.drawMatches(I1, keypts1, I2, keypts2, good_matches, 
                                      None, matchColor=(0, 255, 0), 
                                      singlePointColor=None,
                                      matchesMask=mask_matches, flags=2)
        
        cv2.imshow("Imagen Camara Turtlebot3", img_matches) 
        # cv2.imshow("Imagen Camara Turtlebot3", img_matches)
      else:
         pass
        # print("No hay suficientes correspondencias")

      # Si es que se detecta el objeto
      if object_detected:
        # Se detiene si detecta el objeto
        if not(close):
          twist.linear.x = 0.1
          twist.angular.x = 0.0; twist.angular.y = 0.0; twist.angular.z = 0.0
          
          pub.publish(twist)
        
        #dibujames el bounding box
        num_corners = len(dst_corners)
        for i in range(num_corners):
            x0, y0 = dst_corners[i][0]
            if i == num_corners - 1:
                next_i = 0
            else:
                next_i = i + 1
            x1, y1 = dst_corners[next_i][0]
            cv2.line(I, (x0, y0), (x1, y1), (0, 0, 255), 3, cv2.LINE_AA)
        if lidar.close_point<=0.4:
          twist.linear.x = 0.0
          close = 1
          pub.publish(twist)

      else:
         #poner lo que pasa si no se detecta
        
        twist.linear.x = 0.1; twist.linear.y = 0.0; twist.linear.z = 0.0
        twist.angular.x = 0.0; twist.angular.y = 0.0; twist.angular.z = angular

        angular= angular +0.001

        pub.publish(twist)

      # cv2.imshow("Imagen Camara Turtlebot3", I)  

    # cv2.imshow("Imagen Camara Turtlebot3", I)

    # Esperar al bucle para actualizar
    cv2.waitKey(1)
    # Opcional: publicar la imagen de salida como tópico de ROS
    #pubimg.publish(cam.bridge.cv2_to_imgmsg(I))
    rate.sleep()

cv2.destroyAllWindows()
